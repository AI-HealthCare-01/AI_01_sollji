# services/chat_service.py
import json
import os
from openai import AsyncOpenAI
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from app.models.chat import ChatSession, ChatMessage
import time
import logging

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI í´ë¼ì´ì–¸íŠ¸ â€” ëª¨ë“ˆ ë ˆë²¨ì—ì„œ 1íšŒë§Œ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_client() -> AsyncOpenAI | None:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return None
    return AsyncOpenAI(api_key=api_key)

_openai_client: AsyncOpenAI | None = _build_client()


def get_openai_client() -> AsyncOpenAI:
    if _openai_client is None:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return _openai_client


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# seed_knowledge.json ë¡œë“œ (ì„œë²„ ì‹œìž‘ ì‹œ 1íšŒë§Œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KNOWLEDGE_PATH = os.path.join(os.path.dirname(__file__), "../data/seed_knowledge.json")


def load_knowledge() -> str:
    try:
        with open(KNOWLEDGE_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
        lines = []
        for item in data:
            lines.append(f"[{item['category']}] {item['title']}: {item['content']}")
        return "\n\n".join(lines)
    except Exception:
        return ""


KNOWLEDGE_CONTEXT = load_knowledge()

SYSTEM_PROMPT = f"""ë‹¹ì‹ ì€ ì •í˜•ì™¸ê³¼ ì „ë¬¸ AI ê±´ê°• ìƒë‹´ì‚¬ìž…ë‹ˆë‹¤.
í™˜ìžì˜ ì•½ë¬¼, ìž¬í™œ, ë§Œì„±ì§ˆí™˜ ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.

ì•„ëž˜ëŠ” ì°¸ê³ í•  ì „ë¬¸ ì§€ì‹ìž…ë‹ˆë‹¤:
---
{KNOWLEDGE_CONTEXT}
---

ë‹µë³€ ê·œì¹™:
1. ìœ„ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
2. ì‹¬ê°í•œ ì¦ìƒ(í˜¸í¡ ê³¤ëž€, í‰í†µ, ì˜ì‹ ì €í•˜ ë“±)ì€ ì¦‰ì‹œ ì‘ê¸‰ì‹¤ ë°©ë¬¸ì„ ê¶Œê³ í•˜ì„¸ìš”.
3. ì•½ë¬¼ ìš©ëŸ‰ ë³€ê²½ì´ë‚˜ ì²˜ë°© ë³€ê²½ì€ ë°˜ë“œì‹œ ë‹´ë‹¹ ì˜ì‚¬ì™€ ìƒë‹´í•˜ë„ë¡ ì•ˆë‚´í•˜ì„¸ìš”.
4. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ìž‘ì„±í•˜ì„¸ìš”.
5. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  ì˜ì‚¬ ìƒë‹´ì„ ê¶Œìœ í•˜ì„¸ìš”.
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mock (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© â€” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MOCK_REPLIES = [
    "ì•ˆë…•í•˜ì„¸ìš”! ê±´ê°• ê´€ë ¨ ê¶ê¸ˆí•œ ì ì„ íŽ¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš” ðŸ˜Š",
    "ì•„ëª©ì‹œì‹¤ë¦°ì€ ì‹ì‚¬ì™€ ê´€ê³„ì—†ì´ ë³µìš© ê°€ëŠ¥í•˜ì§€ë§Œ, ìœ„ìž¥ ë¶ˆíŽ¸ê°ì´ ìžˆë‹¤ë©´ ì‹í›„ ë³µìš©ì„ ê¶Œìž¥í•©ë‹ˆë‹¤.",
    "ì´ë¶€í”„ë¡œíŽœì€ ê³µë³µì— ë³µìš©í•˜ë©´ ìœ„ìž¥ ìž¥ì• ê°€ ìƒê¸¸ ìˆ˜ ìžˆìœ¼ë‹ˆ ë°˜ë“œì‹œ ì‹í›„ì— ë³µìš©í•˜ì„¸ìš”.",
    "ì¦ìƒì´ ì§€ì†ëœë‹¤ë©´ ë‹´ë‹¹ ì˜ì‚¬ì™€ ìƒë‹´í•˜ì‹œëŠ” ê²ƒì„ ê¶Œìž¥í•©ë‹ˆë‹¤.",
]

_mock_reply_index = 0


async def _mock_chat(user_message: str) -> str:
    global _mock_reply_index
    reply = MOCK_REPLIES[_mock_reply_index % len(MOCK_REPLIES)]
    _mock_reply_index += 1
    return reply


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¸ì…˜ / ë©”ì‹œì§€ í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def get_or_create_session(
    db: AsyncSession,
    user_id: int,
    session_id: int | None,
    guide_id: int | None,
) -> ChatSession:
    # âœ… 0ì€ Noneìœ¼ë¡œ ì²˜ë¦¬ (Swagger ì‹¤ìˆ˜ ë°©ì–´)
    if session_id == 0:
        session_id = None
    if guide_id == 0:
        guide_id = None

    if session_id:
        result = await db.execute(
            select(ChatSession).where(
                ChatSession.id == session_id,
                ChatSession.user_id == user_id,
                ChatSession.session_status == "ACTIVE",
            )
        )
        session = result.scalar_one_or_none()
        if session:
            return session

    new_session = ChatSession(
        user_id=user_id,
        related_guide_id=guide_id,       # Noneì´ë©´ FK ì•ˆ ê±¸ë¦¼
        context_type="general" if not guide_id else "guide",
        context_id=guide_id,             # Noneì´ë©´ OK
        session_status="ACTIVE",
    )
    db.add(new_session)
    await db.flush()
    return new_session


async def get_session_messages(
    db: AsyncSession,
    session_id: int,
) -> list[dict]:
    result = await db.execute(
        select(ChatMessage)
        .where(ChatMessage.session_id == session_id)
        .order_by(ChatMessage.created_at.asc())
        .limit(20)
    )
    messages = result.scalars().all()
    return [{"role": msg.role, "content": msg.content} for msg in messages]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def chat_with_gpt(
    db: AsyncSession,
    user_id: int,
    user_message: str,
    session_id: int | None = None,
    guide_id: int | None = None,
) -> dict:

    # 1. ì„¸ì…˜ ì¡°íšŒ/ìƒì„±
    session = await get_or_create_session(db, user_id, session_id, guide_id)

    # 2. ì´ì „ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
    history = await get_session_messages(db, session.id)

    # 3. Mock vs Real ë¶„ê¸°
    from app.core.config import get_settings
    settings = get_settings()
    use_mock = getattr(settings, "use_mock_chat", True)

    if use_mock:
        assistant_reply = await _mock_chat(user_message)
    else:
        # GPT ìš”ì²­
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        messages.extend(history)
        messages.append({"role": "user", "content": user_message})

        client = get_openai_client()

        # â±ï¸ latency ì¸¡ì • ì‹œìž‘
        start = time.time()

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=1000,
            temperature=0,
        )

        # â±ï¸ latency ì¸¡ì • ì¢…ë£Œ
        latency_ms = int((time.time() - start) * 1000)
        usage = response.usage

        logger.info(
            f"[LLM] chat | latency={latency_ms}ms | "
            f"prompt_tokens={usage.prompt_tokens} | "
            f"completion_tokens={usage.completion_tokens} | "
            f"total_tokens={usage.total_tokens}"
        )

        assistant_reply = response.choices[0].message.content

    # 4. ì‚¬ìš©ìž ë©”ì‹œì§€ ì €ìž¥
    db.add(ChatMessage(session_id=session.id, role="user", content=user_message))

    # 5. AI ì‘ë‹µ ì €ìž¥
    db.add(ChatMessage(session_id=session.id, role="assistant", content=assistant_reply))

    await db.commit()

    return {
        "session_id": session.id,
        "message": assistant_reply,
        "role": "assistant",
    }


async def end_session(
    db: AsyncSession,
    user_id: int,
    session_id: int,
) -> bool:
    result = await db.execute(
        select(ChatSession).where(
            ChatSession.id == session_id,
            ChatSession.user_id == user_id,
        )
    )
    session = result.scalar_one_or_none()
    if not session:
        return False

    from sqlalchemy.sql import func
    session.session_status = "ENDED"
    session.ended_at = func.now()
    await db.commit()
    return True
